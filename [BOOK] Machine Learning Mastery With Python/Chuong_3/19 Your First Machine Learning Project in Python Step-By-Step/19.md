
# So sánh Mô hình Học máy với Scikit-learn

Đây là đoạn mã Python dùng để đánh giá và so sánh các mô hình học máy khác nhau bằng cách sử dụng thư viện `scikit-learn`.

---

## 1. Tách Dữ Liệu
```python
X = array[:, 0:4]  # Đặc trưng (features)
Y = array[:, 4]    # Nhãn (label)

X_train, X_validation, Y_train, Y_validation = train_test_split(
    X, Y, test_size=0.2, random_state=7)
```
- Dữ liệu được tách thành 80% huấn luyện và 20% kiểm tra.

---

## 2. Khởi Tạo Các Mô Hình
```python
models = [
    ('LR', LogisticRegression()),
    ('LDA', LinearDiscriminantAnalysis()),
    ('KNN', KNeighborsClassifier()),
    ('CART', DecisionTreeClassifier()),
    ('NB', GaussianNB()),
    ('SVM', SVC())
]
```
Danh sách các mô hình được dùng để đánh giá:
- **LR**: Logistic Regression
- **LDA**: Linear Discriminant Analysis
- **KNN**: K-Nearest Neighbors
- **CART**: Decision Tree
- **NB**: Naive Bayes
- **SVM**: Support Vector Machine

---

## 3. Đánh Giá Mô Hình (Cross-Validation)
```python
cv_results = cross_val_score(model, X_train, Y_train, cv=10, scoring='accuracy')
```
- Sử dụng **K-Fold Cross Validation (10 phần)** để đánh giá mô hình.
- Tính độ chính xác trung bình và độ lệch chuẩn.

Ví dụ:
```
KNN: 0.983333 (0.033333)
```

---

## 4. So sánh Trực Quan
```python
pyplot.boxplot(results)
pyplot.show()
```
- Dùng biểu đồ hộp để so sánh hiệu suất các mô hình.
- Cho thấy phân phối điểm số (accuracy) của từng mô hình.

---

## Kết luận
- Đây là quy trình nhanh và hiệu quả để **so sánh nhiều mô hình học máy** trên cùng một tập dữ liệu.
- Giúp chọn ra mô hình tốt nhất dựa trên hiệu suất và độ ổn định.


---

## 5. Đánh Giá Từng Mô Hình

```python
for name, model in models:
    kfold = KFold(n_splits=10, random_state=seed)
    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    names.append(name)
    msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
    print(msg)
```

### Giải thích:
- Với mỗi mô hình, thực hiện K-Fold Cross Validation để đánh giá độ chính xác.
- Kết quả trung bình (`mean`) và độ lệch chuẩn (`std`) được in ra để đánh giá hiệu năng và độ ổn định của mô hình.

### Kết quả mẫu:
```
LR: 0.966667 (0.040825)
LDA: 0.975000 (0.038188)
KNN: 0.983333 (0.033333)
CART: 0.975000 (0.038188)
NB: 0.975000 (0.053359)
SVM: 0.981667 (0.025000)
```

---

## 6. So Sánh Các Mô Hình Qua Biểu Đồ

```python
fig = pyplot.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
pyplot.boxplot(results)
ax.set_xticklabels(names)
pyplot.show()
```

### Giải thích:
- Dùng biểu đồ **boxplot** để trực quan hóa độ chính xác của từng mô hình.
- Giúp dễ dàng so sánh hiệu suất giữa các mô hình.
- Độ dao động nhỏ (hộp nhỏ) và accuracy cao là dấu hiệu của mô hình tốt và ổn định.

---

## Tổng Kết Cuối Cùng

- K-Fold giúp đánh giá mô hình công bằng và không bị lệ thuộc vào một lần chia dữ liệu.
- Dễ dàng so sánh nhiều mô hình khác nhau trên cùng một tập dữ liệu.
- Từ biểu đồ và kết quả thống kê, có thể chọn ra mô hình tốt nhất cho bài toán.



---

## 7. Dự Đoán và Đánh Giá Trên Tập Validation

```python
knn = KNeighborsClassifier()
knn.fit(X_train, Y_train)
predictions = knn.predict(X_validation)

print(accuracy_score(Y_validation, predictions))
print(confusion_matrix(Y_validation, predictions))
print(classification_report(Y_validation, predictions))
```

### Giải thích:
- Mô hình **KNN** được huấn luyện trên `X_train`, `Y_train`.
- Sau đó được dùng để dự đoán nhãn cho `X_validation`.
- Đánh giá mô hình bằng:
  - **accuracy_score**: độ chính xác tổng thể.
  - **confusion_matrix**: ma trận nhầm lẫn, giúp kiểm tra mô hình dự đoán sai ở đâu.
  - **classification_report**: báo cáo chi tiết các chỉ số:
    - **precision**: độ chính xác của từng lớp.
    - **recall**: tỷ lệ phát hiện đúng từng lớp.
    - **f1-score**: trung bình hài hòa giữa precision và recall.
    - **support**: số lượng mẫu thực tế của từng lớp.

### Kết quả mẫu:
```
Accuracy: 0.9

Confusion Matrix:
[[ 7 0 0]
 [ 0 11 1]
 [ 0 2 9]]

Classification Report:
                 precision    recall  f1-score   support
    Iris-setosa       1.00      1.00      1.00         7
Iris-versicolor       0.85      0.92      0.88        12
 Iris-virginica       0.90      0.82      0.86        11
       Accuracy                         0.90        30
```

---

## Kết Luận Cuối Cùng

- Mô hình KNN đạt độ chính xác **90%** trên tập validation.
- Kết quả tốt với lớp "Iris-setosa", nhưng có thể cải thiện thêm với "Iris-virginica".
- Tùy mục tiêu dự án, có thể chọn mô hình tốt hơn từ phần so sánh trước.

---


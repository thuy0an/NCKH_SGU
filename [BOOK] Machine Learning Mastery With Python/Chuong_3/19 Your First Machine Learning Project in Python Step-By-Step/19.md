
# ğŸ“Š So sÃ¡nh MÃ´ hÃ¬nh Há»c mÃ¡y vá»›i Scikit-learn

ÄÃ¢y lÃ  Ä‘oáº¡n mÃ£ Python dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ vÃ  so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y khÃ¡c nhau báº±ng cÃ¡ch sá»­ dá»¥ng thÆ° viá»‡n `scikit-learn`.

---

## 1. ğŸ“‚ TÃ¡ch Dá»¯ Liá»‡u
```python
X = array[:, 0:4]  # Äáº·c trÆ°ng (features)
Y = array[:, 4]    # NhÃ£n (label)

X_train, X_validation, Y_train, Y_validation = train_test_split(
    X, Y, test_size=0.2, random_state=7)
```
- Dá»¯ liá»‡u Ä‘Æ°á»£c tÃ¡ch thÃ nh 80% huáº¥n luyá»‡n vÃ  20% kiá»ƒm tra.

---

## 2. ğŸ¤– Khá»Ÿi Táº¡o CÃ¡c MÃ´ HÃ¬nh
```python
models = [
    ('LR', LogisticRegression()),
    ('LDA', LinearDiscriminantAnalysis()),
    ('KNN', KNeighborsClassifier()),
    ('CART', DecisionTreeClassifier()),
    ('NB', GaussianNB()),
    ('SVM', SVC())
]
```
Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡:
- **LR**: Logistic Regression
- **LDA**: Linear Discriminant Analysis
- **KNN**: K-Nearest Neighbors
- **CART**: Decision Tree
- **NB**: Naive Bayes
- **SVM**: Support Vector Machine

---

## 3. âœ… ÄÃ¡nh GiÃ¡ MÃ´ HÃ¬nh (Cross-Validation)
```python
cv_results = cross_val_score(model, X_train, Y_train, cv=10, scoring='accuracy')
```
- Sá»­ dá»¥ng **K-Fold Cross Validation (10 pháº§n)** Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh.
- TÃ­nh Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n.

VÃ­ dá»¥:
```
KNN: 0.983333 (0.033333)
```

---

## 4. ğŸ“ˆ So sÃ¡nh Trá»±c Quan
```python
pyplot.boxplot(results)
pyplot.show()
```
- DÃ¹ng biá»ƒu Ä‘á»“ há»™p Ä‘á»ƒ so sÃ¡nh hiá»‡u suáº¥t cÃ¡c mÃ´ hÃ¬nh.
- Cho tháº¥y phÃ¢n phá»‘i Ä‘iá»ƒm sá»‘ (accuracy) cá»§a tá»«ng mÃ´ hÃ¬nh.

---

## ğŸ”š Káº¿t luáº­n
- ÄÃ¢y lÃ  quy trÃ¬nh nhanh vÃ  hiá»‡u quáº£ Ä‘á»ƒ **so sÃ¡nh nhiá»u mÃ´ hÃ¬nh há»c mÃ¡y** trÃªn cÃ¹ng má»™t táº­p dá»¯ liá»‡u.
- GiÃºp chá»n ra mÃ´ hÃ¬nh tá»‘t nháº¥t dá»±a trÃªn hiá»‡u suáº¥t vÃ  Ä‘á»™ á»•n Ä‘á»‹nh.


---

## 5. ğŸ§ª ÄÃ¡nh GiÃ¡ Tá»«ng MÃ´ HÃ¬nh

```python
for name, model in models:
    kfold = KFold(n_splits=10, random_state=seed)
    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    names.append(name)
    msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
    print(msg)
```

### âœ… Giáº£i thÃ­ch:
- Vá»›i má»—i mÃ´ hÃ¬nh, thá»±c hiá»‡n K-Fold Cross Validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c.
- Káº¿t quáº£ trung bÃ¬nh (`mean`) vÃ  Ä‘á»™ lá»‡ch chuáº©n (`std`) Ä‘Æ°á»£c in ra Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng vÃ  Ä‘á»™ á»•n Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh.

### ğŸ“Š Káº¿t quáº£ máº«u:
```
LR: 0.966667 (0.040825)
LDA: 0.975000 (0.038188)
KNN: 0.983333 (0.033333)
CART: 0.975000 (0.038188)
NB: 0.975000 (0.053359)
SVM: 0.981667 (0.025000)
```

---

## 6. ğŸ“ˆ So SÃ¡nh CÃ¡c MÃ´ HÃ¬nh Qua Biá»ƒu Äá»“

```python
fig = pyplot.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
pyplot.boxplot(results)
ax.set_xticklabels(names)
pyplot.show()
```

### âœ… Giáº£i thÃ­ch:
- DÃ¹ng biá»ƒu Ä‘á»“ **boxplot** Ä‘á»ƒ trá»±c quan hÃ³a Ä‘á»™ chÃ­nh xÃ¡c cá»§a tá»«ng mÃ´ hÃ¬nh.
- GiÃºp dá»… dÃ ng so sÃ¡nh hiá»‡u suáº¥t giá»¯a cÃ¡c mÃ´ hÃ¬nh.
- Äá»™ dao Ä‘á»™ng nhá» (há»™p nhá») vÃ  accuracy cao lÃ  dáº¥u hiá»‡u cá»§a mÃ´ hÃ¬nh tá»‘t vÃ  á»•n Ä‘á»‹nh.

---

## âœ… Tá»•ng Káº¿t Cuá»‘i CÃ¹ng

- K-Fold giÃºp Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh cÃ´ng báº±ng vÃ  khÃ´ng bá»‹ lá»‡ thuá»™c vÃ o má»™t láº§n chia dá»¯ liá»‡u.
- Dá»… dÃ ng so sÃ¡nh nhiá»u mÃ´ hÃ¬nh khÃ¡c nhau trÃªn cÃ¹ng má»™t táº­p dá»¯ liá»‡u.
- Tá»« biá»ƒu Ä‘á»“ vÃ  káº¿t quáº£ thá»‘ng kÃª, cÃ³ thá»ƒ chá»n ra mÃ´ hÃ¬nh tá»‘t nháº¥t cho bÃ i toÃ¡n.



---

## 7. ğŸ§¾ Dá»± ÄoÃ¡n vÃ  ÄÃ¡nh GiÃ¡ TrÃªn Táº­p Validation

```python
knn = KNeighborsClassifier()
knn.fit(X_train, Y_train)
predictions = knn.predict(X_validation)

print(accuracy_score(Y_validation, predictions))
print(confusion_matrix(Y_validation, predictions))
print(classification_report(Y_validation, predictions))
```

### âœ… Giáº£i thÃ­ch:
- MÃ´ hÃ¬nh **KNN** Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn `X_train`, `Y_train`.
- Sau Ä‘Ã³ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n nhÃ£n cho `X_validation`.
- ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh báº±ng:
  - **accuracy_score**: Ä‘á»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ.
  - **confusion_matrix**: ma tráº­n nháº§m láº«n, giÃºp kiá»ƒm tra mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n sai á»Ÿ Ä‘Ã¢u.
  - **classification_report**: bÃ¡o cÃ¡o chi tiáº¿t cÃ¡c chá»‰ sá»‘:
    - **precision**: Ä‘á»™ chÃ­nh xÃ¡c cá»§a tá»«ng lá»›p.
    - **recall**: tá»· lá»‡ phÃ¡t hiá»‡n Ä‘Ãºng tá»«ng lá»›p.
    - **f1-score**: trung bÃ¬nh hÃ i hÃ²a giá»¯a precision vÃ  recall.
    - **support**: sá»‘ lÆ°á»£ng máº«u thá»±c táº¿ cá»§a tá»«ng lá»›p.

### ğŸ“Š Káº¿t quáº£ máº«u:
```
Accuracy: 0.9

Confusion Matrix:
[[ 7 0 0]
 [ 0 11 1]
 [ 0 2 9]]

Classification Report:
                 precision    recall  f1-score   support
    Iris-setosa       1.00      1.00      1.00         7
Iris-versicolor       0.85      0.92      0.88        12
 Iris-virginica       0.90      0.82      0.86        11
       Accuracy                         0.90        30
```

---

## ğŸ¯ Káº¿t Luáº­n Cuá»‘i CÃ¹ng

- MÃ´ hÃ¬nh KNN Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c **90%** trÃªn táº­p validation.
- Káº¿t quáº£ tá»‘t vá»›i lá»›p "Iris-setosa", nhÆ°ng cÃ³ thá»ƒ cáº£i thiá»‡n thÃªm vá»›i "Iris-virginica".
- TÃ¹y má»¥c tiÃªu dá»± Ã¡n, cÃ³ thá»ƒ chá»n mÃ´ hÃ¬nh tá»‘t hÆ¡n tá»« pháº§n so sÃ¡nh trÆ°á»›c.

---


{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b518fc",
   "metadata": {},
   "source": [
    "# Chương 12 - Spot-Check thuật toán hồi quy\n",
    "\n",
    "Spot-checking là cách để khám phá thuật toán nào hoạt động tốt trên bài toán học máy của bạn. Bạn không thể biết trước thuật toán nào phù hợp nhất với bài toán của mình. Bạn phải thử nhiều phương pháp và tập trung vào những phương pháp chứng tỏ là triển vọng nhất. Trong chương này, bạn sẽ khám phá bảy thuật toán học máy mà bạn có thể sử dụng khi spot-checking bài toán hồi quy của bạn trong Python với scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ea9ef",
   "metadata": {},
   "source": [
    "## 12.1 Tổng quan về thuật toán\n",
    "\n",
    "Trong bài học này, chúng ta sẽ xem xét bảy thuật toán hồi quy mà bạn có thể spot-check trên tập dữ liệu của mình. Bắt đầu với bốn thuật toán học máy tuyến tính:\n",
    "\n",
    "- **Linear Regression**\n",
    "- **Ridge Regression**\n",
    "- **LASSO Linear Regression**\n",
    "- **Elastic Net Regression**\n",
    "\n",
    "Sau đó xem xét ba thuật toán học máy phi tuyến:\n",
    "\n",
    "- **k-Nearest Neighbors**\n",
    "- **Classification and Regression Trees**\n",
    "- **Support Vector Machines**\n",
    "\n",
    "Mỗi ví dụ được trình bày trên tập dữ liệu Boston House Price. Đây là một bài toán hồi quy trong đó tất cả các thuộc tính đều là số. Một test harness với cross validation 10-fold được sử dụng để chứng minh cách spot-check từng thuật toán học máy và các chỉ số mean squared error được sử dụng để chỉ ra hiệu suất thuật toán. Lưu ý rằng giá trị mean squared error bị đảo ngược (âm). Đây là một điểm đặc biệt của hàm `cross_val_score()` được sử dụng, yêu cầu tất cả các chỉ số của thuật toán được sắp xếp theo thứ tự tăng dần (giá trị lớn hơn là tốt hơn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea522e4",
   "metadata": {},
   "source": [
    "## 12.2 Thuật toán học máy tuyến tính\n",
    "\n",
    "Phần này cung cấp các ví dụ về cách sử dụng bốn thuật toán học máy tuyến tính khác nhau cho hồi quy trong Python với scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a45fc",
   "metadata": {},
   "source": [
    "### 12.2.1 Linear Regression\n",
    "\n",
    "Linear regression giả định rằng các biến đầu vào có phân phối Gaussian. Người ta cũng giả định rằng các biến đầu vào có liên quan đến biến đầu ra và chúng không có mối tương quan cao với nhau (một vấn đề gọi là đa cộng tuyến). Bạn có thể xây dựng mô hình hồi quy tuyến tính bằng cách sử dụng lớp `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b46d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69579d32",
   "metadata": {},
   "source": [
    "### 12.2.2 Ridge Regression\n",
    "\n",
    "Ridge regression là một phần mở rộng của linear regression trong đó hàm mất mát được sửa đổi để giảm thiểu độ phức tạp của mô hình đo bằng tổng bình phương của các giá trị hệ số (còn gọi là L2-norm). Bạn có thể xây dựng mô hình ridge regression bằng cách sử dụng lớp `Ridge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137bb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = Ridge()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6554bd6c",
   "metadata": {},
   "source": [
    "### 12.2.3 LASSO Regression\n",
    "\n",
    "Least Absolute Shrinkage and Selection Operator (hay LASSO) là một sự điều chỉnh của hồi quy tuyến tính, giống như ridge regression, trong đó hàm mất mát được sửa đổi để giảm thiểu độ phức tạp của mô hình được đo bằng tổng giá trị tuyệt đối của các giá trị hệ số (còn gọi là L1-norm). Bạn có thể xây dựng mô hình LASSO bằng cách sử dụng lớp `Lasso`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9115bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = Lasso()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87d6de",
   "metadata": {},
   "source": [
    "### 12.2.4 ElasticNet Regression\n",
    "\n",
    "ElasticNet là một dạng hồi quy điều chuẩn kết hợp các đặc tính của cả Ridge Regression và LASSO regression. Nó tìm cách giảm thiểu độ phức tạp của mô hình hồi quy (độ lớn và số lượng hệ số hồi quy) bằng cách phạt mô hình sử dụng cả L2-norm (tổng bình phương giá trị hệ số) và L1-norm (tổng giá trị tuyệt đối hệ số). Bạn có thể xây dựng mô hình ElasticNet bằng cách sử dụng lớp `ElasticNet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = ElasticNet()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca7e3a2",
   "metadata": {},
   "source": [
    "## 12.3 Thuật toán học máy phi tuyến\n",
    "\n",
    "Phần này cung cấp các ví dụ về cách sử dụng ba thuật toán học máy phi tuyến khác nhau cho hồi quy trong Python với scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a4f5c",
   "metadata": {},
   "source": [
    "### 12.3.1 K-Nearest Neighbors\n",
    "\n",
    "Thuật toán k-Nearest Neighbors (hay KNN) định vị k thể hiện tương tự nhất trong tập dữ liệu huấn luyện cho một thể hiện dữ liệu mới. Từ k neighbors, giá trị trung bình hoặc trung vị của biến đầu ra được lấy làm dự đoán. Đáng chú ý là metric khoảng cách được sử dụng (đối số metric). Khoảng cách Minkowski được sử dụng theo mặc định, là một tổng quát hóa của cả khoảng cách Euclidean (được sử dụng khi tất cả các đầu vào có cùng quy mô) và khoảng cách Manhattan (khi quy mô của các biến đầu vào khác nhau). Bạn có thể xây dựng mô hình KNN cho hồi quy bằng cách sử dụng lớp `KNeighborsRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = KNeighborsRegressor()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee2da5",
   "metadata": {},
   "source": [
    "### 12.3.2 Classification and Regression Trees\n",
    "\n",
    "Decision trees hay Classification and Regression Trees (CART) sử dụng dữ liệu huấn luyện để chọn các điểm tốt nhất để chia dữ liệu nhằm giảm thiểu một chỉ số chi phí. Chỉ số chi phí mặc định cho cây quyết định hồi quy là mean squared error, được chỉ định trong tham số criterion. Bạn có thể tạo mô hình CART cho hồi quy bằng cách sử dụng lớp `DecisionTreeRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5bda43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = DecisionTreeRegressor()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a7e3b1",
   "metadata": {},
   "source": [
    "### 12.3.3 Support Vector Machines\n",
    "\n",
    "Support Vector Machines (SVM) được phát triển cho phân loại nhị phân. Kỹ thuật này đã được mở rộng cho các bài toán dự đoán giá trị thực gọi là Support Vector Regression (SVR). Giống như ví dụ phân loại, SVR được xây dựng trên thư viện LIBSVM. Bạn có thể tạo mô hình SVM cho hồi quy bằng cách sử dụng lớp `SVR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = SVR()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c3e92",
   "metadata": {},
   "source": [
    "## 12.4 Tóm tắt\n",
    "\n",
    "Trong chương này, bạn đã khám phá cách spot-check các thuật toán học máy cho các bài toán hồi quy trong Python sử dụng scikit-learn. Cụ thể, bạn đã học về bốn thuật toán học máy tuyến tính: Linear Regression, Ridge Regression, LASSO Linear Regression và Elastic Net Regression. Bạn cũng đã học về ba thuật toán phi tuyến: k-Nearest Neighbors, Classification and Regression Trees và Support Vector Machines."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

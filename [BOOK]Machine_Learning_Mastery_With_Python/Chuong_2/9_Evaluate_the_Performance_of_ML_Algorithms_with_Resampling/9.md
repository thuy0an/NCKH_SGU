# Chương 9 - Đánh giá hiệu suất của thuật toán học máy bằng kỹ thuật lấy mẫu

Trong chương này, bạn sẽ khám phá cách ước tính độ chính xác của các thuật toán học máy bằng phương pháp lấy mẫu lại (resampling) trong Python và scikit-learn. Mục tiêu là đánh giá hiệu suất của thuật toán trên dữ liệu chưa từng thấy bằng cách sử dụng các kỹ thuật thống kê gọi là **lấy mẫu lại**. Dưới đây là các kỹ thuật chính được thảo luận trong chương này:

## 9.1 Đánh giá thuật toán học máy

Khi đánh giá thuật toán học máy, điều quan trọng là tránh overfitting (quá khớp). Overfitting xảy ra khi thuật toán ghi nhớ dữ liệu mà nó được huấn luyện, dẫn đến hiệu suất cao trên dữ liệu huấn luyện nhưng hiệu suất kém trên dữ liệu mới, chưa từng thấy. Để tránh overfitting, chúng ta cần đánh giá thuật toán trên dữ liệu không thuộc quá trình huấn luyện. Việc đánh giá này cung cấp cho chúng ta ước tính về cách mà mô hình có thể hoạt động trên dữ liệu mới.

Có một số kỹ thuật lấy mẫu lại để ước tính hiệu suất của mô hình học máy:

- **Tập huấn luyện và tập kiểm tra (Train and Test Sets)**
- **Kiểm tra chéo K-fold (K-fold Cross Validation)**
- **Kiểm tra chéo Leave One Out (Leave One Out Cross Validation)**
- **Phân chia ngẫu nhiên lặp lại giữa tập huấn luyện và kiểm tra (Repeated Random Test-Train Splits)**

## 9.2 Phân chia thành tập huấn luyện và tập kiểm tra

Kỹ thuật này chia tập dữ liệu thành hai phần: một phần để huấn luyện và một phần để kiểm tra. Mô hình được huấn luyện trên tập huấn luyện và được kiểm tra trên tập kiểm tra. Tỷ lệ phân chia điển hình là **67% cho huấn luyện** và **33% cho kiểm tra**. Mặc dù phương pháp này nhanh và lý tưởng cho các tập dữ liệu lớn, nhưng nó có phương sai cao. Điều này có nghĩa là kết quả có thể thay đổi tùy thuộc vào cách phân chia dữ liệu cụ thể.

### Ưu điểm:
- Nhanh chóng và đơn giản.
- Lý tưởng cho các tập dữ liệu lớn.

### Nhược điểm:
- Phương sai cao trong ước tính hiệu suất do phân chia ngẫu nhiên.

## 9.3 Kiểm tra chéo K-fold

Trong kiểm tra chéo K-fold, tập dữ liệu được chia thành **k** phần (fold). Mô hình được huấn luyện trên **k-1** fold và được kiểm tra trên fold còn lại. Quá trình này được lặp lại cho mỗi fold, cho chúng ta **k** điểm hiệu suất. Giá trị trung bình và độ lệch chuẩn của các điểm số này cung cấp ước tính đáng tin cậy hơn về hiệu suất của mô hình.

### Ưu điểm:
- Đáng tin cậy hơn so với một lần phân chia train-test.
- Giảm phương sai bằng cách sử dụng các tập con khác nhau để huấn luyện và kiểm tra.

### Nhược điểm:
- Tốn kém về mặt tính toán, đặc biệt là với các tập dữ liệu lớn.

## 9.4 Kiểm tra chéo Leave One Out (LOO-CV)

Kiểm tra chéo Leave One Out (LOO-CV) là một trường hợp đặc biệt của kiểm tra chéo K-fold trong đó **k** bằng với số lượng quan sát trong tập dữ liệu. Mỗi phần tử được sử dụng làm tập kiểm tra một lần, trong khi phần còn lại của dữ liệu được sử dụng để huấn luyện. Mặc dù rất kỹ lưỡng, phương pháp này tốn kém về mặt tính toán.

### Ưu điểm:
- Ước tính hiệu suất mô hình rất chi tiết.
- Mỗi điểm dữ liệu đều được sử dụng để kiểm tra.

### Nhược điểm:
- Tốn kém về mặt tính toán.

## 9.5 Phân chia ngẫu nhiên lặp lại giữa tập huấn luyện và kiểm tra

Kỹ thuật này liên quan đến việc lặp lại nhiều lần phân chia ngẫu nhiên tập dữ liệu thành tập huấn luyện và tập kiểm tra. Phương pháp này kết hợp tốc độ của phân chia train-test với lợi ích của kiểm tra chéo, giảm phương sai trong ước tính hiệu suất.

### Ưu điểm:
- Nhanh hơn K-fold và LOO-CV.
- Giảm phương sai bằng cách lặp lại việc đánh giá.

### Nhược điểm:
- Có thể dẫn đến sự dư thừa vì cùng một điểm dữ liệu có thể xuất hiện trong cả tập huấn luyện và tập kiểm tra ở các lần phân chia khác nhau.

## 9.6 Khi nào nên sử dụng những kỹ thuật nào

Dưới đây là một số hướng dẫn để lựa chọn kỹ thuật đánh giá phù hợp:

- **Kiểm tra chéo K-fold** là tiêu chuẩn vàng cho các tập dữ liệu nhỏ đến trung bình. Thông thường, **k = 3, 5, hoặc 10**.
- **Phân chia train/test** hữu ích cho các tập dữ liệu lớn hoặc khi hiệu quả tính toán là quan trọng.
- **Kiểm tra chéo Leave One Out** lý tưởng cho các tập dữ liệu nhỏ nhưng tốn kém về mặt tính toán.
- **Phân chia ngẫu nhiên lặp lại giữa tập huấn luyện và kiểm tra** cung cấp sự cân bằng giữa tốc độ và giảm phương sai.

## 9.7 Tóm tắt

Trong chương này, bạn đã học về các kỹ thuật lấy mẫu lại khác nhau để đánh giá hiệu suất của thuật toán học máy:

- **Tập huấn luyện và tập kiểm tra**
- **Kiểm tra chéo K-fold**
- **Kiểm tra chéo Leave One Out**
- **Phân chia ngẫu nhiên lặp lại giữa tập huấn luyện và kiểm tra**

Mỗi phương pháp đều có ưu điểm và nhược điểm riêng. Kỹ thuật tốt nhất phụ thuộc vào các yếu tố như kích thước tập dữ liệu, chi phí tính toán và nhu cầu về ước tính hiệu suất chính xác. Nếu còn nghi ngờ, **kiểm tra chéo 10-fold** là một lựa chọn an toàn.
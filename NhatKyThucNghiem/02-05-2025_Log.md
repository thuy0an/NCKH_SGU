# Experiment Log - [02-05-2025]

## üéØ M·ª•c ti√™u
- Th·ª±c hi·ªán m√¥ h√¨nh SVM v√† Linear Regression v·ªõi ƒë·∫∑c tr∆∞ng BoW
## üßæ M√¥ t·∫£ th√≠ nghi·ªám
- M√¥ h√¨nh s·ª≠ d·ª•ng: SVM, Linear Regression
- K·ªπ thu·∫≠t ti·ªÅn x·ª≠ l√Ω:
  - Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng
  - Lo·∫°i b·ªè HTML tags v√† k√Ω t·ª± ƒë·∫∑c bi·ªát
  - Lo·∫°i b·ªè c√°c k√≠ t·ª± s·ªë
  - Tokenize
  - Lo·∫°i b·ªè stopwords
  - Lemmatization (s·ª≠ d·ª•ng WordNetLemmatizer)
- Vector h√≥a: Bag of Words (s·ª≠ d·ª•ng CountVectorizer)

## üßë‚Äçüíª Code s·ª≠ d·ª•ng
- Train_SVM_LR_BOW.py (th∆∞ m·ª•c Models)

## ‚úÖ K·∫øt qu·∫£/Th√†nh c√¥ng
### SVM
- Accuracy: 0.734
- Precision: 0.695
- Recall: 0.734
- F1-score: 0.691


### Linear Regression
- Accuracy: 0.436
- Precision: 0.677
- Recall: 0.436
- F1-score: 0.484

## Nh·∫≠n x√©t
- SVM ho·∫°t ƒë·ªông t·ªët v·ªõi ƒë·∫∑c tr∆∞ng 10000, s·ª≠ d·ª•ng LinearSVC thay cho SVC khi ch·∫°y SVM ƒë·ªÉ tƒÉng t·ªëc
- Linear Regression kh√¥ng ph√π h·ª£p v·ªõi b√†i to√°n ph√¢n lo·∫°i do Linear Regression d√†nh cho h·ªìi quy tuy·∫øn t√≠nh

- Trong 4 m√¥ h√¨nh NB, SVM, Logistic Regression v√† Linear Regression th√¨ Logistic Regression v·ªõi ƒë·∫∑c tr∆∞ng BoW c√≥ ƒë·ªô ch√≠nh x√°c cao ƒë·∫°t 76.80%, theo sau l√† SVM v·ªõi ƒë·ªô ch√≠nh x√°c ƒë·∫°t 73.4%
## Code python c·ªßa ng√†y th·ª±c nghi·ªám
```python
import os
import pandas as pd
import numpy as np
from sklearn.svm import LinearSVC
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

# 1. ƒê·ªçc d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
train_preprocessed = pd.read_csv('NCKH_SGU/TrichXuatDacTrung/TrainPreProcess.csv')
test_data = pd.read_csv('NCKH_SGU/TrainAndTestData/test.csv')

def preprocess_Text(text):
    text = text.lower()
    text = re.sub(r'<br\s*/?>', ' ', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    words = word_tokenize(text)
    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]
    return " ".join(words)

# √Åp d·ª•ng ti·ªÅn x·ª≠ l√Ω cho test
test_data['Text_Cleaned'] = test_data['Text'].apply(preprocess_Text)

# Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng BoW cho test
vectorizer = CountVectorizer(max_features=10000)
vectorizer.fit(train_preprocessed['Text_Cleaned'])
X_train = vectorizer.transform(train_preprocessed['Text_Cleaned'])
y_train = train_preprocessed['Score']
X_test = vectorizer.transform(test_data['Text_Cleaned'])
y_test = test_data['Score']

# Ensure the result directory exists
result_dir = os.path.join(os.getcwd(), 'Result')
os.makedirs(result_dir, exist_ok=True)

# 3. Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh SVM v·ªõi LinearSVC
print("\nHu·∫•n luy·ªán m√¥ h√¨nh SVM...")
# S·ª≠ d·ª•ng dual=False cho b·ªô d·ªØ li·ªáu c√≥ nhi·ªÅu m·∫´u h∆°n ƒë·∫∑c tr∆∞ng
n_samples, n_features = X_train.shape
dual_param = n_samples <= n_features

svm_model = LinearSVC(
    C=0.1, 
    random_state=42, 
    dual=dual_param,
    max_iter=2000,  # TƒÉng s·ªë l·∫ßn l·∫∑p
    verbose=1  # Hi·ªÉn th·ªã ti·∫øn tr√¨nh
)
svm_model.fit(X_train, y_train)

# ƒê√°nh gi√° m√¥ h√¨nh SVM
svm_predictions = svm_model.predict(X_test)
svm_report = classification_report(y_test, svm_predictions, output_dict=True)

svm_result_path = os.path.join(result_dir, 'svm_results.txt')
with open(svm_result_path, 'w', encoding='utf-8') as f:
    f.write("K·∫øt qu·∫£ SVM:\n")
    f.write(f"Accuracy: {accuracy_score(y_test, svm_predictions):.3f}\n")
    f.write(f"Precision: {svm_report['weighted avg']['precision']:.3f}\n")
    f.write(f"Recall: {svm_report['weighted avg']['recall']:.3f}\n")
    f.write(f"F1-score: {svm_report['weighted avg']['f1-score']:.3f}\n")

print("\nK·∫øt qu·∫£ SVM:")
print(f"Accuracy: {accuracy_score(y_test, svm_predictions):.3f}")
print(f"Precision: {svm_report['weighted avg']['precision']:.3f}")
print(f"Recall: {svm_report['weighted avg']['recall']:.3f}")
print(f"F1-score: {svm_report['weighted avg']['f1-score']:.3f}")

# 4. Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh Linear Regression
print("\nu·∫•n luy·ªán m√¥ h√¨nh Linear Regression...")
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

lr_predictions = lr_model.predict(X_test)
lr_predictions_rounded = np.round(lr_predictions).astype(int)

lr_report = classification_report(y_test, lr_predictions_rounded, output_dict=True)

lr_result_path = os.path.join(result_dir, 'linear_regression_results.txt')
with open(lr_result_path, 'w', encoding='utf-8') as f:
    f.write("K·∫øt qu·∫£ Linear Regression:\n")
    f.write(f"Accuracy: {accuracy_score(y_test, lr_predictions_rounded):.3f}\n")
    f.write(f"Precision: {lr_report['weighted avg']['precision']:.3f}\n")
    f.write(f"Recall: {lr_report['weighted avg']['recall']:.3f}\n")
    f.write(f"F1-score: {lr_report['weighted avg']['f1-score']:.3f}\n")


print("\nK·∫øt qu·∫£ Linear Regression:")
print(f"Accuracy: {accuracy_score(y_test, lr_predictions_rounded):.3f}")
print(f"Precision: {lr_report['weighted avg']['precision']:.3f}")
print(f"Recall: {lr_report['weighted avg']['recall']:.3f}")
print(f"F1-score: {lr_report['weighted avg']['f1-score']:.3f}")
```
